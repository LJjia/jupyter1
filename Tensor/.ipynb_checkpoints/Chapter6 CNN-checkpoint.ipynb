{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 5 and 3 for 'Conv2D' (op: 'Conv2D') with input shapes: [1,3,3,5], [5,5,3,16].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mH:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    670\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[0;32m    672\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Anaconda\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 5 and 3 for 'Conv2D' (op: 'Conv2D') with input shapes: [1,3,3,5], [5,5,3,16].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5434d4c29187>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0m最后一个padding是填充方法\u001b[0m\u001b[0;31m，\u001b[0m\u001b[1;34m'SAME'\u001b[0m\u001b[0m表示添加全0填充\u001b[0m \u001b[1;34m'VALID'\u001b[0m\u001b[0m表示不添加全0填充\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m '''\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mconv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataSet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilter_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SAME'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;31m#方便为每一个滤波器的输出添加偏置项\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbiases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, name)\u001b[0m\n\u001b[0;32m    397\u001b[0m                                 \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m                                 \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m                                 data_format=data_format, name=name)\n\u001b[0m\u001b[0;32m    400\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    768\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2506\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[0;32m   2507\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2508\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2509\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2510\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1871\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1873\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1874\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1875\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32mH:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[0;32m    611\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 5 and 3 for 'Conv2D' (op: 'Conv2D') with input shapes: [1,3,3,5], [5,5,3,16]."
     ]
    }
   ],
   "source": [
    "#卷积神经网络\n",
    "\n",
    "import tensorflow as tf\n",
    "#通过get_variable创建过滤器的权重变量和偏置项变量\n",
    "#四个维度依次代表 过滤器尺寸（2个维度） 当前层深度 过滤器深度\n",
    "filter_weight=tf.get_variable('weight',[5,5,3,16],initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "biases=tf.get_variable('biases',[16],initializer=tf.constant_initializer(0.1))\n",
    "dataSet = tf.Variable(tf.random_normal([1,3,3,5]))\n",
    "\n",
    "#使用tf.nn.conv2d实现前向传播\n",
    "'''input为4维矩阵，其中第一个维度代表输入是第几张图片，后三维表示输入图片大小、通道数\n",
    "第二个参数输入卷积层权重，\n",
    "第三个参数是不同维度上的步长。长度为4数组，第一维和最后一维都要求是1，中间两维表示长宽上的步长，\n",
    "这意味着不可减少节点矩阵深度或者样例个数\n",
    "最后一个padding是填充方法，'SAME'表示添加全0填充 'VALID'表示不添加全0填充\n",
    "'''\n",
    "conv=tf.nn.conv2d(input,filter_weight,strides=[1,1,1,1],padding='SAME')\n",
    "#池化层过滤器，actived_conv传入当前层节点矩阵。ksize提供了过滤器尺寸，类似的，过滤器只能在一个平面内有效，\n",
    "#所以第一维和最后一维都要求是1，中间两维表示长宽，意味着不可跨不同样例 或者节点矩阵深度\n",
    "#strides提供了步长信息,\n",
    "#tf.nn.avf_pool平均池化层\n",
    "pool=tf.nn.max_pool(actived_conv,ksize=[1,3,3,1],strides=[1,2,2,1],padding='SAME')\n",
    "#方便为每一个滤波器的输出添加偏置项\n",
    "bias=tf.nn.bias_add(conv,biases)\n",
    "#去线性化\n",
    "actived_conv=tf.nn.relu(bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 使用卷积神经网络来识别MNIST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist_inference' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f9715a1012d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m x=tf.placeholder(tf.float32,[\n\u001b[0;32m     27\u001b[0m     \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;31m#一个batch中样例的个数\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mmnist_inference\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;31m#二三维表示图片的尺寸\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mmnist_inference\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     mnist_inference.NUM_CHANNELS],#图片深度，彩色图片深度为3\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mnist_inference' is not defined"
     ]
    }
   ],
   "source": [
    "#mnist_train.py\n",
    "import tensorflow as tf\n",
    "#调整输入数据placeholder的格式，输入为一个四维矩阵\n",
    "\n",
    "#MNIST数据集相关的常数\n",
    "INPUT_NODE=784#像素\n",
    "OUTPUT_NODE=10#区分类别数目\n",
    "#配置神经网络的参数\n",
    "LAYER1_NODE=500#使用一个隐藏层 500个节点  选取的500比784小\n",
    "BATCH_SIZE=100#一个训练batch中的训练数据个数\n",
    "\n",
    "#get variable来获取变量\n",
    "def get_weight_variable(shape,regularizer):\n",
    "    weights=tf.get_variable(\n",
    "    'weights',shape,\n",
    "        initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "\n",
    "\n",
    "\n",
    "LEARNING_RATE_BASE=0.8#基础学习率\n",
    "LEARNING_RATE_DECAY=0.99 #学习率衰减率 指数衰减\n",
    "REGULARIZATION_RATE=0.0001#描述函数模型复杂的的正则化在损失函数中的系数\n",
    "TRAINING_STEPS=1000#训练轮数\n",
    "MOVING_AVERAGE_DECAY=0.9#滑动平均衰减率  滑动平均使用\n",
    "\n",
    "x=tf.placeholder(tf.float32,[\n",
    "    BATCH_SIZE,#一个batch中样例的个数\n",
    "    mnist_inference.IMAGE_SIZE,#二三维表示图片的尺寸\n",
    "    mnist_inference.IMAGE_SIZE,\n",
    "    mnist_inference.NUM_CHANNELS],#图片深度，彩色图片深度为3 灰白为1\n",
    "    name='x-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting D:\\PythonCode\\Machine\\jupyter1\\Tensor\\path/to\\MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting D:\\PythonCode\\Machine\\jupyter1\\Tensor\\path/to\\MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting D:\\PythonCode\\Machine\\jupyter1\\Tensor\\path/to\\MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting D:\\PythonCode\\Machine\\jupyter1\\Tensor\\path/to\\MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "3136\n",
      "Tensor(\"Mean:0\", shape=(), dtype=float32) Tensor(\"AddN:0\", shape=(), dtype=float32)\n",
      "After 100 training step(s),validation accuracyusing average model is 0.07\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "INPUT_NODE=784#像素\n",
    "OUTPUT_NODE=10#区分类别数目\n",
    "\n",
    "\n",
    "IMAGE_SIZE=28\n",
    "NUM_CHANNELS=1\n",
    "NUM_LABELS=10\n",
    "BATCH_SIZE=100\n",
    "#第一层卷积网络的尺寸和深度  5*5*32\n",
    "CONV1_DEEP=32 \n",
    "CONV1_SIZE=5\n",
    "#第二层卷积网络的尺寸和深度  5*5*32\n",
    "CONV2_DEEP=64\n",
    "CONV2_SIZE=5\n",
    "#全连接层节点个数\n",
    "FC_SIZE=512\n",
    "#定义前向传播过程\n",
    "\n",
    "'''学习率这个参数的取值很重要，这里如果取用0.8，会出现飙升'''\n",
    "LEARNING_RATE_BASE=0.001#基础学习率\n",
    "LEARNING_RATE_DECAY=0.99 #学习率衰减率 指数衰减\n",
    "REGULARIZATION_RATE=0.0001#描述函数模型复杂的的正则化在损失函数中的系数\n",
    "TRAINING_STEPS=100#训练轮数\n",
    "MOVING_AVERAGE_DECAY=0.99#滑动平均衰减率  滑动平均使用\n",
    "\n",
    "def inference(input_tensor,train,regularizer):\n",
    "    #第一层输入28*28*1 输出28*28*32\n",
    "    with tf.variable_scope('layer1-conv1'):\n",
    "        conv1_weights=tf.get_variable(\n",
    "        'weight',[CONV1_SIZE,CONV1_SIZE,NUM_CHANNELS,CONV1_DEEP],\n",
    "        initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        conv1_biases=tf.get_variable(\n",
    "        'bias',[CONV1_DEEP],initializer=tf.constant_initializer(0.0))\n",
    "        \n",
    "        #使用边长为5，深度为32的过滤器，过滤器移动步长为1，且全部使用0填充\n",
    "        conv1=tf.nn.conv2d(\n",
    "        input_tensor,conv1_weights,strides=[1,1,1,1],padding='SAME')\n",
    "        relu1=tf.nn.relu(tf.nn.bias_add(conv1,conv1_biases))#使用方便加和的函数\n",
    "    \n",
    "    #实现第二层池化层前向传播过程\n",
    "    with tf.name_scope('layer2-pool1'):\n",
    "        pool1=tf.nn.max_pool(\n",
    "        relu1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "        \n",
    "        \n",
    "    #第三层 输入14*14*32矩阵 输出14*14*64\n",
    "    with tf.variable_scope('layer3-conv2'):\n",
    "        conv2_weights=tf.get_variable(\n",
    "        'weight',[CONV2_SIZE,CONV2_SIZE,CONV1_DEEP,CONV2_DEEP],#命名空间不同 ，前缀不同\n",
    "        initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        conv2_biases=tf.get_variable(\n",
    "        'bias',[CONV2_DEEP],\n",
    "        initializer=tf.constant_initializer(0.0))\n",
    "        #使用边长5，深度64的过滤器，过滤器步长1 全0填充\n",
    "        conv2=tf.nn.conv2d(\n",
    "            pool1,conv2_weights,strides=[1,1,1,1],padding='SAME')\n",
    "        relu2=tf.nn.relu(tf.nn.bias_add(conv2,conv2_biases))\n",
    "    \n",
    "    #第四层池化层 尺寸和步长\n",
    "    with tf.variable_scope('layer4-pool2'):\n",
    "        pool2=tf.nn.max_pool(\n",
    "        relu2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    #即使关闭了上下文管理器，pool2在外部也可以调用，只不过pool2此变量的名字前面会加上前缀,注意不是变量名\n",
    "    \n",
    "    #将第四层池化层转化为全连接层的输入格式\n",
    "    '''第四层输出为7*7*64矩阵，第五层全连接层需要将其拉成一个直线向量'''\n",
    "    #此函数可以直接获得第四层输出矩阵的维度，不需手工计算，但是因为输入为一个bacth矩阵，\n",
    "    #因此这里得到的维度也包含了一个batch中数据个数\n",
    "    pool_shape=pool2.get_shape().as_list()\n",
    "    #计算拉直之后的维度 pool_shape[0]存储batch中数据个数\n",
    "    nodes=pool_shape[1]*pool_shape[2]*pool_shape[3]#nodes=3136\n",
    "    print(nodes)\n",
    "    #通过tf.reshape转换第四层的输出 把pool2转化为batch_size*nodes的大小\n",
    "    reshaped=tf.reshape(pool2,[pool_shape[0],nodes])\n",
    "    \n",
    "    #第五层前向传播过程 输入3136 输出512维度向量\n",
    "    '''改进：引入了dropout，训练时会随机将部分节点的输出改为0，相当于随机降维，可以有效避免过拟合问题\n",
    "    dropout一般只在全连接层使用，池化层和卷积层都不使用'''\n",
    "    with tf.variable_scope('layer5-fc1'):\n",
    "        fc1_weights=tf.get_variable(\n",
    "        'weight',[nodes,FC_SIZE],\n",
    "        initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        #只有全连接层的权重参数需要正则化\n",
    "        if regularizer!=None:\n",
    "            tf.add_to_collection('losses',regularizer(fc1_weights))\n",
    "        fc1_biases=tf.get_variable(\n",
    "            'bias',[FC_SIZE],initializer=tf.constant_initializer(0.1))\n",
    "        fc1=tf.nn.relu(tf.matmul(reshaped,fc1_weights)+fc1_biases)\n",
    "        if train:\n",
    "            fc1=tf.nn.dropout(fc1,0.5)\n",
    "            \n",
    "    #第六层全连接层的变量实现前向传播过程 输入512 输出 长度10  该层输出经过softmax后得到最后的分类结果\n",
    "    with tf.variable_scope('layer6-fc2'):\n",
    "        fc2_weights=tf.get_variable(\n",
    "        'weight',[FC_SIZE,NUM_LABELS],\n",
    "        initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        if regularizer!=None:\n",
    "            tf.add_to_collection('losses',regularizer(fc2_weights))\n",
    "        fc2_biases=tf.get_variable(\n",
    "            'bias',[NUM_LABELS],initializer=tf.constant_initializer(0.1))\n",
    "        logit=tf.matmul(fc1,fc2_weights)+fc2_biases\n",
    "    \n",
    "    return logit\n",
    "\n",
    "\n",
    "#定义训练模型的过程\n",
    "def train(mnist):\n",
    "    x=tf.placeholder(tf.float32,[\n",
    "        BATCH_SIZE,#一个batch中样例的个数\n",
    "        IMAGE_SIZE,#二三维表示图片的尺寸\n",
    "        IMAGE_SIZE,\n",
    "        NUM_CHANNELS],#图片深度，彩色RGB图片深度为3灰白为1\n",
    "        name='x-input')\n",
    "\n",
    "    y_=tf.placeholder(tf.float32,[None,OUTPUT_NODE],name='y-input')#y_表示真实值\n",
    "    \n",
    "    regularizer=tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)\n",
    "    y=inference(x,train=False,regularizer=regularizer)\n",
    "    \n",
    "\n",
    "    #定义训练轮数 因为不适应滑动平均值 因此可以指定为不可训练的变量\n",
    "    global_step=tf.Variable(0,trainable=False)\n",
    "\n",
    "    #给定滑动平均衰减率和训练轮数 初始化滑动平均类\n",
    "    variable_averages=tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY,global_step)\n",
    "\n",
    "    #在所有代表神经网络参数的变量上使用滑动平均  滑动平均维护一个影子变量，程序中直接使用了这个影子变量\n",
    "    #tf.trainable_variables()返回计算图中可以训练的变量，即trainable=True的参数\n",
    "    variables_averages_op=variable_averages.apply(tf.trainable_variables())\n",
    "\n",
    "    #tf.argmax(y_,1) y_为输入序列 argmax表示选取最大值，其中参数1表示仅在第一个维度中执行，也就是说选取每行中最大值的对应下标\n",
    "    #y_有多少行 tf.argmax(y_,1)返回一个长度为多少的数组\n",
    "    #此函数第一个参数y为训练结果，第二个参数为正确答案\n",
    "    cross_entropy=tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y,labels=tf.argmax(y_,1))\n",
    "    '''注意，在这里是使用正常的变量维护来进行  训练  数据，但是使用滑动平均来  测试  训练结果的准确性'''\n",
    "    '''y这里的取值是一个十维的数组，每个元素取值都可以是0-1之间的小数，此函数大概是寻找这些维度与对应0-9标签之间的联系\n",
    "    使用softmax层进行优化，计算多分类问题的交叉熵\n",
    "    交叉熵越小，两个事件发生的概率分布越接近，证明预测值越接近实际值'''\n",
    "    #求平均\n",
    "    cross_entropy_mean=tf.reduce_mean(cross_entropy)\n",
    "    print(cross_entropy_mean,tf.add_n(tf.get_collection('losses')))\n",
    "\n",
    "#     #计算L2正则化损失函数\n",
    "#     regularizer=tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)\n",
    "#     #计算模型的正则化损失\n",
    "#     regularization=regularizer(weights1)+regularizer(weights2)\n",
    "#总损失等交叉熵损失和正则损失和\n",
    "    loss=cross_entropy_mean + tf.add_n(tf.get_collection('losses'))#从losses集合中获取了l2正则化的值 见88行\n",
    "    #设置指数衰减的学习率   未设置stairacase=True则是连续指数衰减\n",
    "    learning_rate=tf.train.exponential_decay(\n",
    "        LEARNING_RATE_BASE,#基础学习率\n",
    "        global_step,#当前迭代轮数\n",
    "        mnist.train.num_examples/BATCH_SIZE,#过完所有的训练数据需要的迭代次数\n",
    "        LEARNING_RATE_DECAY#学习率衰减速度\n",
    "    )\n",
    "    #使用优化器  这个优化器的学习率是呈指数衰减的，并且是一个梯度衰减\n",
    "    train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)\n",
    "    '''建立依赖关系train_op必须在train_step,variables_averages_op激活之后才执行'''\n",
    "    with tf.control_dependencies([train_step,variables_averages_op]):\n",
    "        train_op=tf.no_op(name='train')\n",
    "    #tf.no_op表示什么都不做，这里的含义就是体格train_op包含了train_step,variables_averages_op这两个执行\n",
    "     \n",
    "    correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))    \n",
    "        \n",
    "    #初始化会话\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        '''这里不再把训练数据和测试数据放在一个函数中执行，测试数据单独写一个函数'''\n",
    "        \n",
    "        #迭代训练数据\n",
    "        for i in range(TRAINING_STEPS):\n",
    "            xs,ys=mnist.train.next_batch(BATCH_SIZE)#选取数据\n",
    "            reshape_xs=np.reshape(xs,(BATCH_SIZE,\n",
    "                                      IMAGE_SIZE,\n",
    "                                      IMAGE_SIZE,\n",
    "                                      NUM_CHANNELS))\n",
    "            #这里的_,很奇怪 仅表示一个临时变量\n",
    "            _,loss_value,step=sess.run([train_op,loss,global_step],feed_dict={x:reshape_xs,y_:ys})\n",
    "            if i %10==0:          \n",
    "                print('After %d training step(s),loss on training batch'\n",
    "                      ' is %g'%(step,loss_value))\n",
    "        test_xs,test_ys=mnist.test.next_batch(BATCH_SIZE)#选取数据\n",
    "        reshape_test_xs=np.reshape(test_xs,(BATCH_SIZE,\n",
    "                                          IMAGE_SIZE,\n",
    "                                          IMAGE_SIZE,\n",
    "                                          NUM_CHANNELS))\n",
    "        test_feed={x:reshape_test_xs,\n",
    "                      y_:test_ys}\n",
    "        test_acc=sess.run(accuracy,feed_dict=test_feed)#accury 为100一个模型的平均正确率\n",
    "        #打印最终正确率\n",
    "        print('After %d training step(s),validation accuracy'\n",
    "                      'using average model is %g'%(global_step,test_acc))\n",
    "\n",
    "        \n",
    "#对于台式机电脑，使用路径为\n",
    "#mnist=input_data.read_data_sets('D:\\PythonCode\\jupyter\\Machine\\Tensor\\path/to\\MNIST_data',one_hot=True)\n",
    "#而笔记本电脑的路径为\n",
    "mnist=input_data.read_data_sets('D:\\PythonCode\\Machine\\jupyter1\\Tensor\\path/to\\MNIST_data',one_hot=True)\n",
    "train(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 测试文件\n",
    "#此文件运行时需先运行上面的文件\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "def evaluate(mnist):\n",
    "    with tf.Graph().as_default() as g:\n",
    "        #定义输入格式\n",
    "        x=tf.placeholder(\n",
    "            tf.float32,[None ,INPUT_NODE],name='x-input')\n",
    "        y_=tf.placeholder(\n",
    "            tf.float32,[None,OUTPUT_NODE],name='y-output')\n",
    "        validate_feed={x:mnist.validation.images,\n",
    "                       y_:mnist.validation.labels}\n",
    "        #不计算正则化\n",
    "        \n",
    "        y=inference(x,0,None)\n",
    "        #计算前向传播的正确率\n",
    "        #tf.argmax(y,1) 可得到输入样例的预测类别\n",
    "        correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "        accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))#tf.cast转化数据格式\n",
    "        variable_averages=tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY)\n",
    "        variables_to_restore=variable_averages.variables_to_restore()\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            accuracy_score=sess.run(accuracy,feed_dict=validate_feed)\n",
    "            print('After %s training steps ,validation accuracy=%g'\n",
    "                 %(global_step,accuracy_score))\n",
    "#对于台式机电脑，使用路径为\n",
    "#mnist=input_data.read_data_sets('D:\\PythonCode\\jupyter\\Machine\\Tensor\\path/to\\MNIST_data',one_hot=True)\n",
    "#而笔记本电脑的路径为\n",
    "mnist=input_data.read_data_sets('D:\\PythonCode\\Machine\\jupyter1\\Tensor\\path/to\\MNIST_data',one_hot=True)\n",
    "evaluate(mnist)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting D:\\PythonCode\\Machine\\jupyter1\\Tensor\\path/to\\MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting D:\\PythonCode\\Machine\\jupyter1\\Tensor\\path/to\\MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting D:\\PythonCode\\Machine\\jupyter1\\Tensor\\path/to\\MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting D:\\PythonCode\\Machine\\jupyter1\\Tensor\\path/to\\MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 4 but is rank 2 for 'layer1-conv1/Conv2D' (op: 'Conv2D') with input shapes: [?,784], [5,5,1,32].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mH:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    670\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[0;32m    672\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Anaconda\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Shape must be rank 4 but is rank 2 for 'layer1-conv1/Conv2D' (op: 'Conv2D') with input shapes: [?,784], [5,5,1,32].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-84461b8451b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m#而笔记本电脑的路径为\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:\\PythonCode\\Machine\\jupyter1\\Tensor\\path/to\\MNIST_data'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-84461b8451b4>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(mnist)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m#不计算正则化\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;31m#计算前向传播的正确率\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m#tf.argmax(y,1) 可得到输入样例的预测类别\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-00a644c9ab4a>\u001b[0m in \u001b[0;36minference\u001b[1;34m(input_tensor, train, regularizer)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;31m#使用边长为5，深度为32的过滤器，过滤器移动步长为1，且全部使用0填充\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         conv1=tf.nn.conv2d(\n\u001b[1;32m---> 42\u001b[1;33m         input_tensor,conv1_weights,strides=[1,1,1,1],padding='SAME')\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mrelu1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconv1_biases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#使用方便加和的函数\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, name)\u001b[0m\n\u001b[0;32m    397\u001b[0m                                 \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m                                 \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m                                 data_format=data_format, name=name)\n\u001b[0m\u001b[0;32m    400\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    768\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2506\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[0;32m   2507\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2508\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2509\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2510\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1871\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1873\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1874\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1875\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32mH:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[0;32m    611\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape must be rank 4 but is rank 2 for 'layer1-conv1/Conv2D' (op: 'Conv2D') with input shapes: [?,784], [5,5,1,32]."
     ]
    }
   ],
   "source": [
    "# 测试文件\n",
    "#此文件运行时需先运行上面的文件\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "def evaluate(mnist):\n",
    "    with tf.Graph().as_default() as g:\n",
    "        #定义输入格式\n",
    "        x=tf.placeholder(\n",
    "            tf.float32,[None ,INPUT_NODE],name='x-input')\n",
    "        y_=tf.placeholder(\n",
    "            tf.float32,[None,OUTPUT_NODE],name='y-output')\n",
    "        validate_feed={x:mnist.validation.images,\n",
    "                       y_:mnist.validation.labels}\n",
    "        #不计算正则化\n",
    "        \n",
    "        y=inference(x,0,None)\n",
    "        #计算前向传播的正确率\n",
    "        #tf.argmax(y,1) 可得到输入样例的预测类别\n",
    "        correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "        accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))#tf.cast转化数据格式\n",
    "        variable_averages=tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY)\n",
    "        variables_to_restore=variable_averages.variables_to_restore()\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            accuracy_score=sess.run(accuracy,feed_dict=validate_feed)\n",
    "            print('After %s training steps ,validation accuracy=%g'\n",
    "                 %(global_step,accuracy_score))\n",
    "#对于台式机电脑，使用路径为\n",
    "#mnist=input_data.read_data_sets('D:\\PythonCode\\jupyter\\Machine\\Tensor\\path/to\\MNIST_data',one_hot=True)\n",
    "#而笔记本电脑的路径为\n",
    "mnist=input_data.read_data_sets('D:\\PythonCode\\Machine\\jupyter1\\Tensor\\path/to\\MNIST_data',one_hot=True)\n",
    "evaluate(mnist)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
